# -*- coding: utf-8 -*-
"""Churn Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OO4q7n8OxeVDSKqleQ0T8rLdaxEwPUEw

#1. Data set review & preparation

Tujuan :
1. Untuk memahami dataset
2. Untuk mempersiapkan dataset untuk tugas eksplorasi dan prediksi
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
pd.options.display.max_rows = 30
pd.options.display.max_columns = 20

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Portofolio/Churn Prediction/Churn_Modelling.csv')
df.head()

"""Dataset Description:

1. **RowNumber**: corresponds to the record (row) number and has no effect on the output.
2. **CustomerId**: contains random values and has no effect on customer leaving the bank.
3. **Surname**: the surname of a customer has no impact on their decision to leave the bank.
4. **CreditScore**: can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.
5. **Geography**: a customer’s location can affect their decision to leave the bank.
6. **Gender**: it’s interesting to explore whether gender plays a role in a customer leaving the bank.
7. **Age**: this is certainly relevant, since older customers are less likely to leave their bank than younger ones.
8. **Tenure**: refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.
9. **Balance**: also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.
10. **NumOfProducts**: refers to the number of products that a customer has purchased through the bank.
11. **HasCrCard**: denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.
12. **IsActiveMember**: active customers are less likely to leave the bank.
13. **EstimatedSalary**: as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.
14. **Exited**: whether or not the customer left the bank. (0=No,1=Yes)
"""

# Tipe data dari masing-masing variabel
types = df.dtypes
print(type(types))
types

# Jumlah nilai unik dari masing-masing variabel
distinct = df.nunique()
print(type(distinct))
distinct

# Jumlah data yang kosong atau tidak memiliki nilai atau NaN atau Null atau missing value
count_na = df.isna().sum()
print(type(count_na))
count_na

# Persentase data yang kosong atau tidak memiliki nilai atau NaN atau Null atau missing value
percent_na = round((df.isna().sum()/len(df))*100, 3)
print(type(percent_na))
percent_na

data = pd.concat([types, distinct, count_na, percent_na], axis=1)
data.rename(columns = {'index': 'column' , 0:'types', 1:'distinct', 2:'count_na', 3: 'percent_na'}, inplace = True)
print(type(data))
data

# Hapus kolom RowNumber, CustomerId, Surname
df = df.drop(['RowNumber', 'CustomerId', 'Surname'],axis = 1)

"""#2. Exploratory Data Analysis"""

# Hubungan Nasabah Churn dengan Variabel Kategori
fig, axarr = plt.subplots(2, 2, figsize = (20, 12))
sns.countplot(x='Geography', hue = 'Exited', data = df, ax=axarr[0][0])
sns.countplot(x='Gender', hue = 'Exited', data = df, ax=axarr[0][1])
sns.countplot(x='HasCrCard', hue = 'Exited', data = df, ax=axarr[1][0])
sns.countplot(x='IsActiveMember', hue = 'Exited', data = df, ax=axarr[1][1])

"""Note:

* Berdasarkan geografi, proporsi nasabah yang keluar (exited) lebih banyak berasal dari German, sedangkan untuk Prancis dan Spanyol cenderung lebih rendah.
* Berdasarkan jenis kelamin, proporsi nasabah yang keluar (exited) lebih banyak Perempuan, dibandingkan dengan laki - laki.
* Berdasrkan kepemilikan Credit Card, proporsi nasabah yang keluar (exited) lebih banyak berasal dari nasabah yang memiliki Credit Card, dibandingkan dengan nasabar yang tidak memiliki Credit Card.
* Berdarkan active member, proporsi nasabah yang keluar (exited) lebih banyak berdarkan nasabah yang sudah di cap tidak aktif, dibandingkan dengan nasabah yang masih aktif.
"""

# Hubungan Nasabah Churn dengan Variabel Kontinu
fig, axarr = plt.subplots(3, 2, figsize = (20, 12))
sns.boxplot(y = 'CreditScore', x = 'Exited', hue = 'Exited', data = df, ax = axarr[0][0])
sns.boxplot(y = 'Age', x = 'Exited', hue = 'Exited', data = df, ax = axarr[0][1])
sns.boxplot(y = 'Tenure', x = 'Exited', hue = 'Exited', data = df, ax = axarr[1][0])
sns.boxplot(y = 'Balance', x = 'Exited', hue = 'Exited', data = df, ax = axarr[1][1])
sns.boxplot(y = 'NumOfProducts', x = 'Exited', hue = 'Exited', data = df, ax = axarr[2][0])
sns.boxplot(y = 'EstimatedSalary', x = 'Exited', hue = 'Exited', data = df, ax = axarr[2][1])

"""* Untuk Credit Score, tidak ada perbedaan yang signifikan antara nasabah exited dan nasabah tidak exited.
* Untuk Umur, nasabah yang exited mayoritas orang orang yang umurnya lebih tua (umur 40 - 60), dibandingkan dengan nasabah yang lebih muda (umur 30 - 40).
* Untuk Tenure, mediannya hampir sama, untuk mayoritas data bereda di selang yang hampir sama.
* Untuk Balance, nasabah exited adalah orang orang yang memiliki balance kecil menengah mayoritasnya.
* Untuk NumOfProduct dan EstimatedSalary tidak terlalu terlihat polanya, hampir sama berdasarkan boxplot.

## Correlation Matrix
"""

#Nasabah Churn correlation matrix
cm = df.corr()
plt.figure(figsize = (10, 6))
sns.heatmap(cm, annot = True, cmap = 'viridis')

"""Note :

Dari Correlation Matrix
teresebut dapat dilihat tidak
ada nilai korelasi yang terlalu
besar antara variabel.
"""

# Plot Nasabanh Churn
sns.countplot(x = 'Exited', data = df)

"""sekitar 20% dari nasabah telah bergejolak. Sehingga model dasarnya dapat memprediksi bahwa 20% nasabah akan churn. Mengingat 20% adalah angka kecil, kita perlu memastikan bahwa model yang dipilih benar-benar memprediksi dengan sangat akurat 20% ini karena menarik bagi bank untuk mengidentifikasi dan menyimpan kelompok ini sebagai lawan memprediksi secara akurat pelanggan yang dipertahankan. Bisa dilihat ini adalah kasus inbakande, maka nanti akan diatasi dengan menggunakan Resampling menggunakan SMOTE.

#3. Features Engineering

Akan ditambahkan fitur tambahan yang mungkin berdampak pada kemungkinan churning
"""

df_fe = df.copy()

# Belance Salary Ratio
df_fe['BalanceSalaryRatio'] = df_fe['Balance']/df_fe['EstimatedSalary']

# Tenure By Age
df_fe['TenureByAge'] = df_fe['Tenure']/df_fe['Age']

# Credit score given age
df_fe['CreditScoreGivenAge'] = df_fe['CreditScore']/df_fe['Age']

df_fe.head()

"""#4. Data preparation for model fitting"""

# One hot encode untuk variabel kategorik
from sklearn.preprocessing import OneHotEncoder
lst = ['Geography','Gender']
ohe = OneHotEncoder()
ohe.fit(df_fe[lst])
df_ohe_res = pd.DataFrame(ohe.transform(df_fe[lst]).toarray(),
                          columns = ohe.get_feature_names_out())
df_fe = pd.concat([df_fe, df_ohe_res], axis=1)
df_fe.drop(columns=lst, inplace=True)
df_fe.head()

# minMax scaling untuk variabel kontinu
from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
mm.fit(df_fe)
df_fe = pd.DataFrame(mm.transform(df_fe), columns=df_fe.columns)
df_fe.head()

from sklearn.model_selection import train_test_split

# Split Train, test data
x = df_fe.drop(columns = ['Exited']).copy()
y = df_fe['Exited'].copy()
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)
print(len(x_train))
print(len(x_test))

"""#5. Model fitting and selection

For the model fitting, I will try out the following
* Logistic regression
* KNN
* Ensemble models

"""

# Fit models
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# Scoring functions
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

"""## Fit best Models"""

# Fit logistic regression
log = LogisticRegression()
log.fit(x_train, y_train)

# Fit KNN
knn = KNeighborsClassifier()
knn.fit(x_train, y_train)

# Fit Random Forest Classifier
rf = RandomForestClassifier()
rf.fit(x_train, y_train)

"""## Review best model fit accuracy"""

y_pred_log = log.predict(x_test)
print(classification_report(y_test, y_pred_log))

y_pred_knn = knn.predict(x_test)
print(classification_report(y_test, y_pred_knn))

y_pred_rf = rf.predict(x_test)
print(classification_report(y_test, y_pred_rf))

"""dari 3 model yang paling bagus adalah Model Random
Forest Classifier, karena memiliki nilai precision, recall, f1-score
yang paling tinggi dibandinkan dengan 2 model yang lainnya.
"""

def get_auc_scores(y_actual, y_pred, y_proba):
  auc_score = roc_auc_score(y_actual, y_pred);
  fpr_df, tpr_df, _=roc_curve(y_actual, y_proba);
  return (auc_score, fpr_df, tpr_df)

auc_log, fpr_log, tpr_log = get_auc_scores(y,
                                          log.predict(x),
                                          log.predict_proba(x)[:,1])
auc_knn, fpr_knn, tpr_knn = get_auc_scores(y,
                                          knn.predict(x),
                                          knn.predict_proba(x)[:,1])
auc_rf, fpr_rf, tpr_rf = get_auc_scores(y,
                                        rf.predict(x),
                                        rf.predict_proba(x)[:,1])

plt.figure(figsize = (12,6), linewidth = 1)
plt.plot(fpr_log, tpr_log, label = 'log Score:' + str(round(auc_log,5)))
plt.plot(fpr_knn, tpr_knn, label = 'knn Score:' + str(round(auc_knn,5)))
plt.plot(fpr_rf, tpr_rf, label = 'rf Score:' + str(round(auc_rf,5)))
plt.plot([0,1], [0,1], 'k--', 'label = Random : 0.5')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC Curve')
plt.legend(loc='best')
plt.show()

"""Kurva Random Forest Classifier adalah
kurva yang paling akurat karena kurva
random forest classifier paling mendekati
sudut kiri atas. Sebaliknya kurva logistic
regression adalah kurva yang paling tidak
akurat karena kurva logistic regression
mendekati diagonal 45 derajat dari ruang
ROC.

##Resampling to handle imbalanced dataset
"""

from imblearn.over_sampling import SMOTE
oversample = SMOTE()
x_smote, y_smote = oversample.fit_resample(x_train, y_train)

y_train.value_counts()

y_smote.value_counts()

# Fit Random Forest Classifier
rf_smote = RandomForestClassifier()
rf_smote.fit(x_smote, y_smote)

y_pred_smote = rf_smote.predict(x_test)
print(classification_report(y_test, y_pred_smote))

"""Jika dibandingkan hasil pengujian sebelum
Resampling dengan setelah resampling, resampling yang
dilakukan tidak terlalu meningkatkan prediksi. tetapi resampling
yang dilakukan meningkatkan nilai recall yang menjadi lebih
besar yaitu 0,76 dibandingkan model awal memiliki 0,72. Maka
saya akan memilih model yang baru yang telah di lakukan
resampling karena utk kasus imbalace lebih baik kita mencari
yang nilai recall nya baik.

## Feature Importance
"""

fi = rf_smote.feature_importances_
col = x_train.columns
plt.barh(col, fi)

"""Dari plot disamping, kita dapat melihat
bahwa variabel 'Age' adalah variabel
yang paling membantu model untuk
membedakan nasabah churn atau
tidak churn.
"""

df.groupby('Exited')['Age'].mean()

pd.crosstab(df['NumOfProducts'], df['Exited'])

